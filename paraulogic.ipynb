{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import unidecode\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar diccionari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Font: https://github.com/Softcatala/catalan-dict-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adjectius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "acostumat acostumada [sup. acostumadíssim]=categories: A; font: DIEC;\n",
    "acotiledoni acotiledònia=categories: A;fonts: LT;\n",
    "acotonat -ada=categories: A;fonts: AVL;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (arrel_path / \"adjectius-fdic.txt\").open() as f:\n",
    "    lines3 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ítric',\n",
       " 'òctuple',\n",
       " 'òctuple',\n",
       " 'òhmic',\n",
       " 'òmnibus',\n",
       " 'òntic',\n",
       " 'òptic',\n",
       " 'òptim',\n",
       " 'òrfic',\n",
       " 'òrquic',\n",
       " 'òrtic',\n",
       " 'òsmic',\n",
       " 'òtic',\n",
       " 'úgric',\n",
       " 'últim',\n",
       " 'úmbric',\n",
       " 'únic',\n",
       " 'úric',\n",
       " 'ústaixa',\n",
       " 'útil']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex1 = re.compile(r'^(.+?)[\\s=\\d]')\n",
    "\n",
    "def parse(l, add_suffix=True):\n",
    "    res = None\n",
    "    if l[0] != '#':\n",
    "        m = regex1.search(l)\n",
    "        if m:\n",
    "            p1 = m.group(1)\n",
    "            res = (p1, )\n",
    "    return res\n",
    "\n",
    "paraules3 = [parse(l) for l in lines3[:]]\n",
    "paraules3 = [x for x in paraules3 if x is not None]\n",
    "paraules3 = [y for x in paraules3 for y in x]\n",
    "print(len(paraules3))\n",
    "paraules3[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adverbis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "crescendo crescendo RG\n",
    "curt curt RG\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (arrel_path / \"adverbis-lt.txt\").open() as f:\n",
    "    lines4 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tostemps',\n",
       " 'tot',\n",
       " 'total',\n",
       " 'tothora',\n",
       " 'totjorn',\n",
       " 'trinco-trinco',\n",
       " 'verbigràcia',\n",
       " 'viceversa',\n",
       " 'vv',\n",
       " 'xano-xano',\n",
       " 'xau-xau',\n",
       " 'xino-xano',\n",
       " 'xiu-xiu',\n",
       " 'àdhuc',\n",
       " 'àlies',\n",
       " 'ça',\n",
       " 'ídem',\n",
       " 'ínterim',\n",
       " 'ítem',\n",
       " 'òlim']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraules4 = [parse(l) for l in lines4[:]]\n",
    "paraules4 = [x for x in paraules4 if x is not None]\n",
    "paraules4 = [y for x in paraules4 for y in x]\n",
    "print(len(paraules4))\n",
    "paraules4[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adverbis-ment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "adelitadament adelitadament RG # extrets de corpus\n",
    "adequadament adequadament RG\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (arrel_path / \"adverbis-ment-lt.txt\").open() as f:\n",
    "    lines5 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['àticament',\n",
       " 'àtonament',\n",
       " 'àuriament',\n",
       " 'àvidament',\n",
       " 'àvolment',\n",
       " 'èbriament',\n",
       " 'èpicament',\n",
       " 'èticament',\n",
       " 'ètnicament',\n",
       " 'ímprobament',\n",
       " 'ínfimament',\n",
       " 'íntegrament',\n",
       " 'íntimament',\n",
       " 'òbviament',\n",
       " 'ònticament',\n",
       " 'òpticament',\n",
       " 'òptimament',\n",
       " 'últimament',\n",
       " 'únicament',\n",
       " 'útilment']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraules5 = [parse(l) for l in lines5[:]]\n",
    "paraules5 = [x for x in paraules5 if x is not None]\n",
    "paraules5 = [y for x in paraules5 for y in x]\n",
    "print(len(paraules5))\n",
    "paraules5[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "baralluga=categories: F;fonts: DNV;\n",
    "barastell=categories: M;fonts: DNV;\n",
    "barbadià -ana=categories: A;fonts: DNV;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrel_path = Path(\"catalan-dict-tools-master/diccionari-arrel\")\n",
    "with (arrel_path / \"dnv-fdic.txt\").open() as f:\n",
    "    lines1 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xequeig',\n",
       " 'xequera',\n",
       " 'xibar',\n",
       " 'xibó',\n",
       " 'xifarrera',\n",
       " 'xilladissa',\n",
       " 'xillador',\n",
       " 'xilladora',\n",
       " 'xillar',\n",
       " 'xillit',\n",
       " 'ximenera',\n",
       " 'xinesc',\n",
       " 'xinesca',\n",
       " 'xinxiró',\n",
       " 'xiqüelina',\n",
       " 'xirigotada',\n",
       " 'xiritxofla',\n",
       " 'xirlis-mirlis',\n",
       " 'xirnac',\n",
       " 'xirnàs',\n",
       " 'xirolita',\n",
       " 'xiste',\n",
       " 'xistós',\n",
       " 'xistosa',\n",
       " 'xitxa',\n",
       " 'xitxarrot',\n",
       " 'xitxina',\n",
       " 'xitxorrita',\n",
       " 'xiuleter',\n",
       " 'xiuletera',\n",
       " 'xofa',\n",
       " 'xofir',\n",
       " 'xoneta',\n",
       " 'xopera',\n",
       " 'xorripapa',\n",
       " 'xorrit',\n",
       " 'xoto',\n",
       " 'xoto',\n",
       " 'xuflaina',\n",
       " 'xuplallànties',\n",
       " 'xuplamel·lo',\n",
       " 'xurruplar',\n",
       " 'xurrutada',\n",
       " 'xuïta',\n",
       " 'xàrnera',\n",
       " 'zulo',\n",
       " 'àntrex',\n",
       " 'àstrofe',\n",
       " 'èbola',\n",
       " 'òfsai']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = re.compile(r'^(.+?)[=\\s]')\n",
    "regex2 = re.compile(r'^(.+?)\\s-(.+)=')\n",
    "def parse(l, add_suffix=True):\n",
    "    res = None\n",
    "    if l[0] != '#':\n",
    "        p = regex.search(l).group(1)\n",
    "        res = (p,)\n",
    "        m = regex2.search(l)\n",
    "        if m and add_suffix:\n",
    "            # Intentem trobar la forma feminina considerant les ùltimes lletres\n",
    "            suffix = m.group(2)\n",
    "            if len(suffix) == 1:\n",
    "                p2 = p + suffix\n",
    "            else:\n",
    "                letter = suffix[0]\n",
    "                unaccented_p = unidecode.unidecode(p)\n",
    "                for i in range(-1, -4, -1):\n",
    "                    if unaccented_p[i] == letter:\n",
    "                        break\n",
    "                i = len(unaccented_p) + i\n",
    "                # check that the rest of the suffix matches the end of the word\n",
    "                # No, this is not true, for example\n",
    "                # ajardinat -ada\n",
    "#                 for j in range(i + 1, len(unaccented_p)):\n",
    "#                     assert unaccented_p[j] == suffix[j - i]\n",
    "#                     print(j, unaccented_p[j] == suffix[j - i])\n",
    "                # Build the word by replacing the end by the suffix\n",
    "                p2 = p[:i] + suffix[:]\n",
    "                \n",
    "            res = (p, p2)\n",
    "    return res\n",
    "\n",
    "paraules1 = [parse(l) for l in lines1[:]]\n",
    "paraules1 = [x for x in paraules1 if x is not None]\n",
    "paraules1 = [y for x in paraules1 for y in x]\n",
    "print(len(paraules1))\n",
    "paraules1[-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "alcoholar=categories: V;model:cantar;fonts:LT\n",
    "alcoholificar=categories: V;model:trencar;fonts:LT\n",
    "alcoholitzar=categories: V;model:cantar;fonts:LT\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (arrel_path / \"verbs-fdic.txt\").open() as f:\n",
    "    lines2 = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xauxinar',\n",
       " 'xauxinejar',\n",
       " 'xemicar',\n",
       " 'xericar',\n",
       " 'xeringar',\n",
       " 'xerocopiar',\n",
       " 'xerografiar',\n",
       " 'xerracar',\n",
       " 'xerraquejar',\n",
       " 'xerrar',\n",
       " 'xerricar',\n",
       " 'xerrotejar',\n",
       " 'xifrar',\n",
       " 'xilografiar',\n",
       " 'ximplejar',\n",
       " 'xinar',\n",
       " 'xinxollar',\n",
       " 'xipollar',\n",
       " 'xipollejar',\n",
       " 'xiquejar',\n",
       " 'xirigar',\n",
       " 'xiriguejar',\n",
       " 'xisclar',\n",
       " 'xisquejar',\n",
       " 'xitar',\n",
       " 'xiular',\n",
       " 'xiuxiuar',\n",
       " 'xiuxiuejar',\n",
       " 'xivar',\n",
       " 'xivatar',\n",
       " 'xocar',\n",
       " 'xollar',\n",
       " 'xopar',\n",
       " 'xopinejar',\n",
       " 'xorrar',\n",
       " 'xorrencar',\n",
       " 'xuclar',\n",
       " 'xuixar',\n",
       " 'xumar',\n",
       " 'xuplar',\n",
       " 'xurmar',\n",
       " 'xurriaquejar',\n",
       " 'xutar',\n",
       " 'zefirar',\n",
       " 'zelar',\n",
       " 'zenkeritzar',\n",
       " 'zigzaguejar',\n",
       " 'zincar',\n",
       " 'zonificar',\n",
       " 'zumzejar']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraules2 = [parse(l) for l in lines2[:]]\n",
    "paraules2 = [x for x in paraules2 if x is not None]\n",
    "paraules2 = [y for x in paraules2 for y in x]\n",
    "print(len(paraules2))\n",
    "paraules2[-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Juntar tots els sub-diccionaris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47572\n"
     ]
    }
   ],
   "source": [
    "paraules = paraules1 + paraules2 + paraules3 + paraules4 + paraules5\n",
    "# sense el DNV\n",
    "paraules = paraules2 + paraules3 + paraules4 + paraules5\n",
    "paraules = [re.sub(r'-', r'', x) for x in paraules]\n",
    "print(len(paraules))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrar diccionari per trobar les paraules vàlides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abacallanar\n",
      "Counter({'a': 5, 'l': 2, 'b': 1, 'c': 1, 'n': 1, 'r': 1})\n",
      "{'i', 's', 'r', 'd', 'o', 'b', 'e'}\n",
      "{'a', 'n', 'l', 'c'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraulogic_optional = list(\"rsodei\")\n",
    "paraulogic_magic = \"b\"\n",
    "\n",
    "def test_word(p, verbose=0):\n",
    "    if verbose >= 1: print(p)\n",
    "    p1 = unidecode.unidecode(p).lower()\n",
    "    count = Counter(p1)\n",
    "    # La lletra màgica ha d'apareixer en la paraula\n",
    "    valid1 = paraulogic_magic in count.keys()\n",
    "    if verbose >= 1: print(count)\n",
    "    # La paraula només pot fer servir la lletra màgica i lletres opcionals\n",
    "    if verbose >= 1: print(set(paraulogic_optional + [paraulogic_magic]))\n",
    "    valid2 = len(set(count.keys()) - set(paraulogic_optional + [paraulogic_magic])) == 0\n",
    "    if verbose >= 1: print(set(count.keys()) - set(paraulogic_optional + [paraulogic_magic]))\n",
    "    valid = valid1 and valid2\n",
    "    return valid\n",
    "    \n",
    "# Exemple\n",
    "p = paraules[0]\n",
    "test_word(p, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['borir',\n",
       " 'desobeir',\n",
       " 'obeir',\n",
       " 'obrir',\n",
       " 'obsedir',\n",
       " 'rebordeir',\n",
       " 'rebre',\n",
       " 'reobrir',\n",
       " 'bederrès',\n",
       " 'berber',\n",
       " 'beró',\n",
       " 'bessó',\n",
       " 'bo',\n",
       " 'bobo',\n",
       " 'bodo',\n",
       " 'boirós',\n",
       " 'bord',\n",
       " 'bordisser',\n",
       " 'borrer',\n",
       " 'borrós',\n",
       " 'briós',\n",
       " 'brosser',\n",
       " 'brossós',\n",
       " 'bòer',\n",
       " 'ebri',\n",
       " 'iber',\n",
       " 'ibier',\n",
       " 'obeïdor',\n",
       " 'obrer',\n",
       " 'obridor',\n",
       " 'obsés',\n",
       " 'obès',\n",
       " 'orb',\n",
       " 'orber',\n",
       " 'rebedor',\n",
       " 'rebò',\n",
       " 'rober',\n",
       " 'seborroide',\n",
       " 'serbi',\n",
       " 'sibírid',\n",
       " 'sobrebò',\n",
       " 'sobrer',\n",
       " 'sobri',\n",
       " 'sobí',\n",
       " 'bis',\n",
       " 'bé',\n",
       " 'dessobre',\n",
       " 'rebé',\n",
       " 'sobre']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p for p in paraules if test_word(p)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
